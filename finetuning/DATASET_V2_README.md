# LAMP Training Dataset v2

## Overview

Expanded fine-tuning dataset for the LAMP smart light controller. Trains small language models (3-4B params) to translate natural language requests into structured JSON light programs for a 172-LED lamp (10x14 front grid + 32 ambient back LEDs).

**Generated**: February 11, 2026
**Method**: Team of 5 Claude agents generating responses in parallel (no API cost)
**Previous dataset**: v1 with 2,521 examples

---

## Files

| File | Examples | Purpose |
|------|----------|---------|
| `data/train_v2.jsonl` | 6,567 | Training split (90%) |
| `data/val_v2.jsonl` | 730 | Validation split (10%) |
| **Total** | **7,297** | |

Each line is a JSON object with a `conversations` array containing three turns:
1. **system**: The lamp programmer system prompt (from `llm/prompts.py`)
2. **user**: `"Create a light program for this request.\n\nRequest: {prompt}\n\nRespond with ONLY a JSON program. No text."`
3. **assistant**: A compact JSON lamp program

---

## Verification Results

Verified with `verify_dataset.py` — **100% pass rate, 0 issues**.

| Check | Result |
|-------|--------|
| Valid JSON (all responses) | 7,297 / 7,297 (100%) |
| Valid program structure | 7,297 / 7,297 (100%) |
| Valid hex colors | 40,817 valid, 0 invalid |
| Grid bounds (x:0-9, y:0-13) | 0 violations |
| Unique prompts | 7,297 (0 duplicates) |
| System prompt present | 7,297 / 7,297 |

---

## Dataset Composition

### Source Breakdown

| Source | Count | Description |
|--------|-------|-------------|
| v1 (original) | 2,521 | Original dataset from API-generated responses |
| v2 (new) | 4,776 | New examples generated by Claude agent team |

### Category Distribution (v2 new data)

| Category | Count | Description |
|----------|-------|-------------|
| render_diverse | ~800 | Pixel art for 130+ unique objects (animals, nature, food, tech, vehicles, buildings, faces, holidays) |
| contextual | ~800 | Time-of-day, activity, mood, weather, and season-aware requests |
| conversational | ~600 | Vague, follow-up, question-as-request, multi-intent, verbose/rambling prompts |
| pattern | ~500 | Gradients, named effects (northern lights, lava lamp), synesthetic descriptions |
| multi_step | ~500 | Story sequences, nature simulations, routines, games, celebrations |
| creative | ~500 | Emotions, abstract concepts, cultural references, sensory descriptions |
| mixed | ~400 | Render + pattern combos, text + pattern transitions |
| seasonal_holiday | ~300 | Christmas, Halloween, Valentine's, New Year, Easter, Diwali, Hanukkah, etc. |
| text | ~300 | Text display, emoji pixel art, countdowns, status displays |
| edge_case | ~300 | Contradictions, impossible requests, typos/SMS, multilingual, very short/long |

### Command Type Distribution

| Command Type | Count (across all steps) |
|-------------|--------------------------|
| pattern | 8,774 |
| render | 3,347 |
| stop | 1 |

### Pattern Usage

| Pattern | Count | Use Case |
|---------|-------|----------|
| solid | 2,710 | Simple color displays, focus lighting |
| breathing | 1,545 | Calm, sleep, meditation, anxiety relief |
| gradient | 1,483 | Warm ambiance, moods, backgrounds |
| sparkle | 1,065 | Celebrations, night sky, festive effects |
| wave | 1,058 | Ocean, nature, energy, transitions |
| pulse | 589 | Alerts, lightning, heartbeat effects |
| rainbow | 324 | Celebrations, surprise, party mode |

### Program Complexity

| Steps | Count | % |
|-------|-------|---|
| 1 step (static) | 5,169 | 70.8% |
| 2 steps | 836 | 11.5% |
| 3 steps | 494 | 6.8% |
| 4+ steps | 798 | 10.9% |
| Has loop | 786 | 10.8% |
| Has on_complete | 204 | 2.8% |

### Prompt Length Distribution

| Length | Count | % | Target |
|--------|-------|---|--------|
| Short (1-3 words) | 1,601 | 22% | 30% |
| Medium (4-8 words) | 4,120 | 56% | 40% |
| Long (9+ words) | 1,576 | 22% | 30% |

Average: 6.7 words/prompt (up from 5.3 in v1)

### Render Statistics

| Metric | Value |
|--------|-------|
| Total render commands | 3,347 |
| Avg elements per render | 8.6 |
| Min elements | 1 |
| Max elements | 57 |
| Pixel elements | 20,270 |
| Rect elements | 3,370 |
| Fill elements | 3,337 |
| Text elements | 1,198 |
| Line elements | 479 |

---

## Improvements Over v1

### 1. Heart Bias Fix
v1 had only 1 pixel art example in the system prompt (heart). The new dataset includes 130+ unique pixel art subjects across animals, nature, food, tech, vehicles, buildings, faces, and holiday objects.

### 2. Contextual Awareness (NEW)
800 prompts teaching the model to interpret context:
- Time: "it's 7am, ease me into the day" → warm sunrise gradient
- Activity: "about to start a zoom call" → cool focus white
- Mood: "I'm feeling anxious" → slow blue breathing
- Weather: "it's snowing outside" → warm gradient
- Season: "first day of autumn" → amber wave

### 3. Conversational Realism (NEW)
600 prompts matching real voice-first speech patterns:
- Vague: "do something nice", "surprise me", "you pick"
- Follow-up style: "make it brighter", "same but in blue"
- Questions: "what would look good for a date night?"
- Multi-intent: "show a star and make it sparkle"
- Rambling: "so like, I was thinking, maybe something warm but not too warm..."

### 4. Multi-Step Diversity
Reduced timer dominance (was 44% of multi-step). New sequences include:
- Story arcs (dark → tension → climax → resolve)
- Nature simulations (dawn to dusk, seasons)
- Morning/evening routines
- Interactive games (Simon says, color roulette)
- Celebration countdowns

### 5. Seasonal/Holiday Coverage (NEW)
300 prompts for 10+ holidays: Christmas, Halloween, Valentine's, New Year, Easter, 4th of July, Diwali, Chinese New Year, Hanukkah, plus general celebrations (birthday, graduation, baby shower) and seasonal events (first snow, cherry blossom, harvest moon).

### 6. Edge Case Handling
300 prompts for graceful degradation:
- Typos/SMS: "blu lgt pls" → solid blue
- Contradictions: "bright but dark" → white sparkle on black
- Impossible: "play music" → thematic light program
- Multilingual: "montre-moi un coeur" → heart render

---

## Generation Method

### Phase 1: Prompt Generation
5,000 new prompts generated across 10 categories with natural language variation (same request phrased 3-5 ways). Each prompt sounds like a real person talking to their lamp via voice.

### Phase 2: Response Generation (Agent Team)
Instead of API calls, a team of 5 Claude (Sonnet) agents generated responses in parallel:

| Agent | Categories | Prompts |
|-------|-----------|---------|
| Agent 1 | render_diverse + mixed | 828 |
| Agent 2 | contextual + mixed | 828 |
| Agent 3 | contextual + conversational + edge_case | 828 |
| Agent 4 | multi_step + pattern + edge_case | 828 |
| Agent 5 | seasonal_holiday + text + creative | 830 |

Each agent received:
- Full lamp system prompt with all commands
- Category-specific generation guidelines
- Example responses for their category types
- Quality rules (valid JSON, correct grid bounds, thematic colors)

### Phase 3: Merge & Validation
- All agent outputs merged and deduplicated
- Combined with v1 data (2,521 examples)
- Validated: JSON structure, program schema, hex colors, grid bounds
- Shuffled and split 90/10 for train/val

---

## Training Recommendations

Based on the dataset plan:
- **Epochs**: 2 (not 3, since dataset is ~3x larger than v1)
- **Same hyperparameters**: LR, batch size, optimizer as v1
- **Models**: Llama 3.2 3B, Gemma 3 4B, Phi-4 Mini
- **Framework**: Unsloth with bf16

---

## File Reference

| File | Description |
|------|-------------|
| `data/train_v2.jsonl` | Training data (6,567 examples) |
| `data/val_v2.jsonl` | Validation data (730 examples) |
| `data/prompts_v2.jsonl` | All v2 prompts (4,985) |
| `data/responses_chunk_{1-5}.jsonl` | Raw agent outputs |
| `verify_dataset.py` | Verification script |
| `merge_and_format.py` | Merge/dedup/format script |
| `prepare_remaining.py` | Chunk splitting utility |
| `DATASET_EXPANSION_PLAN.md` | Original planning document |
